{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pGAORVDUHtQV"
   },
   "source": [
    "# **Preprocessing: convert images into numpy array**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iPZUIptJ5CQt"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported\n"
     ]
    }
   ],
   "source": [
    "# importing \n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, BatchNormalization\n",
    "\n",
    "print(\"Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FMizz_hj_NeY"
   },
   "source": [
    "## Dataset preparation and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "HDcEG2hD5Kcj"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 1546/1546 [00:00<00:00, 81482.71it/s]\n",
      "100%|██████████████████████████████████████| 15086/15086 [00:01<00:00, 12594.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples for train:  15086\n",
      "Total samples for test:  1546\n",
      "14900 unique train patients\n",
      "1522 unique test patients\n",
      "7966 5451 1483\n",
      "885 591 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "INPUT_SIZE = (128, 128)  # change size to (224, 224) and (229, 229) and repeat to get all the arrays\n",
    "mapping = {'normal': 0, 'pneumonia': 1, 'COVID-19': 2}\n",
    "train_filepath = 'train_split.txt'\n",
    "test_filepath = 'test_split.txt'\n",
    "\n",
    "# load in the train and test files\n",
    "file = open(train_filepath, 'r')\n",
    "trainfiles = file.readlines()\n",
    "file = open(test_filepath, 'r')\n",
    "testfiles = file.readlines()\n",
    "\n",
    "# [FROM HERE] next two cycles do nothing: just to discover unique patient's distribution\n",
    "arr1 = []\n",
    "arr2 = []\n",
    "p1 = 0\n",
    "c1 = 0\n",
    "n1 = 0\n",
    "p2 = 0\n",
    "c2 = 0\n",
    "n2 = 0\n",
    "for i in tqdm(range(len(testfiles))):\n",
    "    test_i = testfiles[i].split()\n",
    "    if (test_i[0] not in arr2):\n",
    "        arr2.append(test_i[0])\n",
    "        if(test_i[2] == 'pneumonia'):\n",
    "            p1+=1\n",
    "        if(test_i[2] == 'COVID-19'):\n",
    "            c1+=1\n",
    "        if(test_i[2] == 'normal'):\n",
    "            n1+=1\n",
    "for i in tqdm(range(len(trainfiles))):\n",
    "    test_i = trainfiles[i].split()\n",
    "    if (test_i[0] not in arr1):\n",
    "        arr1.append(test_i[0])\n",
    "        if(test_i[2] == 'pneumonia'):\n",
    "            p2+=1\n",
    "        if(test_i[2] == 'COVID-19'):\n",
    "            c2+=1\n",
    "        if(test_i[2] == 'normal'):\n",
    "            n2+=1      \n",
    "print('Total samples for train: ', len(trainfiles))\n",
    "print('Total samples for test: ', len(testfiles))\n",
    "print(len(arr1), 'unique train patients')\n",
    "print(len(arr2), 'unique test patients')\n",
    "print(n2,p2,c2)\n",
    "print(n1,p1,c1)\n",
    "# [TO HERE]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "nkd9aTmq5U_t"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████| 1546/1546 [00:15<00:00, 99.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In x_test we have 1546 test images and their shape is (229, 229, 3)\n",
      "In y_text we have 1546 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# resize to input size and normalize to 0 - 1\n",
    "x_test = []\n",
    "y_test = []\n",
    "\n",
    "for i in tqdm(range(len(testfiles))):\n",
    "    test_i = testfiles[i].split()\n",
    "    imgpath = test_i[1]\n",
    "    img = cv2.imread(os.path.join('data', 'test', imgpath))\n",
    "    img = cv2.resize(img, INPUT_SIZE)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    x_test.append(img)\n",
    "    y_test.append(mapping[test_i[2]])\n",
    "\n",
    "print('In x_test we have', len(x_test), 'test images and their shape is', x_test[0].shape)\n",
    "print('In y_text we have', len(y_test), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WIoMx0mz5YVe"
   },
   "outputs": [],
   "source": [
    "# export to npy to load in for testing\n",
    "np.save('data/x_test_229.npy', x_test)\n",
    "np.save('data/y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "CoIiTGPqK2Y4"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 15086/15086 [02:38<00:00, 95.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In x_train we have 15086 train images and their shape is (229, 229, 3)\n",
      "In y_train we have 15086 labels\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# resize to input size and normalize to 0 - 1\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in tqdm(range(len(trainfiles))):\n",
    "    train_i = trainfiles[i].split()\n",
    "    imgpath = train_i[1]\n",
    "    img = cv2.imread(os.path.join('data', 'train', imgpath))\n",
    "    img = cv2.resize(img, INPUT_SIZE)\n",
    "    img = img.astype('float32') / 255.0\n",
    "    x_train.append(img)\n",
    "    y_train.append(mapping[train_i[2]])\n",
    "    \n",
    "print('In x_train we have', len(x_train), 'train images and their shape is', x_train[0].shape)\n",
    "print('In y_train we have', len(y_train), 'labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "QMXautwpGFGB"
   },
   "outputs": [],
   "source": [
    "# export to npy to load in for training\n",
    "np.save('data/x_train_128.npy', x_train)\n",
    "np.save('data/y_train.npy', y_train)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "celltoolbar": "Raw Cell Format",
  "colab": {
   "collapsed_sections": [],
   "name": "PreProcessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 304.28738,
   "position": {
    "height": "39.997px",
    "left": "878.882px",
    "right": "20px",
    "top": "44.9778px",
    "width": "627.978px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
